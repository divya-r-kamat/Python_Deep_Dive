## Python Datastructure and Alorithms

Big(O) notation is a language we use to talk about how long a algorithm takes to run, we can compare two different algorithm or functions using Big(O) to find which one is better that the other with regards to scale regardless of our machine/conputer differences.

We measure Big(O) using below graph, it means when we go bigger and bigger with our input how much does the algorithm or function slow down or the number of operations that we need to do as the inpur increases. This is called algorithmic efficiency, different functions have differnt big-O complexities. The less or lower it slows down the better it is.

<img src="https://user-images.githubusercontent.com/42609155/121635235-8a145380-caa3-11eb-843b-62698516a85c.png" width="500">


- O(n) - This is one of the most common Big-O notation, it indicates that as the number of inputs (n) increase, the number of operations also increases, also called as Linear Time.

- O(1) - This is called Constant time, no matter how many inputs we have the number of operation is just one or constant amount of time.
